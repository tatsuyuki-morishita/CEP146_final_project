# References and Sources

1.  **Samsung Data Leak (2023)**: Samsung engineers pasted proprietary code into ChatGPT.
2.  **Cyberhaven Report**: "11% of data pasted into ChatGPT is confidential."
3.  **Perplexity Comet Exploit**: Exploited through a hidden spoiler tag on Reddit.
4.  **Anthropic Research**: Without safeguards, prompt injection attacks succeed about 24% of the time.
5.  **Tea App Data Leak (July 2025)**: Dating app "Tea" exposed 72,000+ users due to insecure AI-generated Firebase configuration.
6.  **Study on AI Code**: "48% of AI-generated code contains some kind of vulnerability."
7.  **Andrej Karpathy**: Coined the term "Vibe Coding" in February 2025.
