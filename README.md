# AI Security: Hidden Risks of the AI Revolution

**Team Members:**
- Tatsuyuki Morishita (108776253)
- Elmira Huseynzade (114652258)

## Topic Summary
This project explores the security risks associated with using Artificial Intelligence tools, focusing on three specific areas that affect everyday users:
1.  **Data Leaks in AI Chats**: How confidential information is inadvertently shared with model trainers.
2.  **AI Agents and Prompt Injection**: Vulnerabilities arising from AI agents interacting with web content and active user sessions.
3.  **Vibe Coding**: Security flaws introduced by code generated by AI without sufficient human review.

## Key Findings
-   **Data Leaks**: 11% of data pasted into ChatGPT is confidential.
-   **Prompt Injection**: AI agents can be manipulated by hidden text on websites to perform unauthorized actions using the user's session.
-   **Generated Code Vulnerabilities**: 48% of AI-generated code contains vulnerabilities.

## Final Discussion Question
Traditional security relies on strict rules, but AI relies on flexible interpretation of language. Given that this flexibility is what makes AI useful, is it possible to ever make AI completely secure, or must we accept a new baseline of risk in exchange for its capabilities?

## Video
https://youtu.be/k8IWDorS55E

## References
See [SOURCES.md](SOURCES.md) for a full list of references.